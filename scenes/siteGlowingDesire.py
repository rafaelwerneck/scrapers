import re
import requests
import scrapy
from tpdb.BaseSceneScraper import BaseSceneScraper


class SiteGlowingDesireSpider(BaseSceneScraper):
    name = 'GlowingDesire'
    network = 'Glowing Desire'
    parent = 'Glowing Desire'
    site = 'Glowing Desire'
    start_urls = [
        'https://glowingdesire.com',
    ]

    selector_map = {
        'title': '//h2/text()',
        'description': '//div[@class="content"]/p//text()',
        'date': '//span[@class="date"]/text()',
        'date_formats': ['%b %d, %Y'],
        'image': '//video/@poster',
        'performers': '//div[contains(@class, "content-pane-performers")]/a/text()',
        'tags': '//div[contains(@class, "categories")]/a/text()',
        'external_id': r'stream/(\d+)/',
        'pagination': '/video/gallery/%s',
        'type': 'Scene',
    }
    
    def get_next_page_url(self, base, page):
        if int(page) == 1:
            return self.format_url(base, '/video/gallery/')
        else:
            page = str((int(page) - 1) * 12)
            return self.format_url(base, f'/video/gallery/{page}/')
        
    def get_scenes(self, response):
        meta = response.meta
        scenes = response.xpath('//div[contains(@class, "overlay-item")]/a/@href').getall()
        for scene in scenes:
            if re.search(self.get_selector_map('external_id'), scene):
                yield scrapy.Request(url=self.format_link(response, scene), callback=self.parse_scene, meta=meta)
